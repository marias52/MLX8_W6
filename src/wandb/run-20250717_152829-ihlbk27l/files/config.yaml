_wandb:
    value:
        cli_version: 0.21.0
        e:
            0qk0h89h96fnh2qq5nv30uy3p25j9ujf:
                codePath: src/sft_train.py
                codePathLocal: sft_train.py
                email: mariasharif.16@hotmail.com
                executable: /Users/admin/Documents/ml_learning/week_6/preference_optimisation/.venv/bin/python3
                git:
                    commit: 60e99e32175bf4d0a4b0f1cf7e39fc5f0476f119
                    remote: https://github.com/marias52/MLX8_W6.git
                host: maria-2.local
                os: macOS-14.5-arm64-arm-64bit
                program: /Users/admin/Documents/ml_learning/week_6/preference_optimisation/src/sft_train.py
                python: CPython 3.10.18
                root: /Users/admin/Documents/ml_learning/week_6/preference_optimisation/src
                startedAt: "2025-07-17T14:28:29.429378Z"
                writerId: 0qk0h89h96fnh2qq5nv30uy3p25j9ujf
        m: []
        python_version: 3.10.18
        t:
            "1":
                - 1
                - 11
                - 41
                - 49
                - 51
                - 71
                - 98
            "2":
                - 1
                - 11
                - 41
                - 49
                - 51
                - 71
                - 98
            "3":
                - 2
                - 16
            "4": 3.10.18
            "5": 0.21.0
            "6": 4.53.2
            "12": 0.21.0
            "13": darwin-arm64
batch_size:
    value: 2
eval_steps:
    value: 100
gradient_accumulation_steps:
    value: 8
learning_rate:
    value: 0.0002
logging_steps:
    value: 10
lora_alpha:
    value: 16
lora_dropout:
    value: 0.1
lora_rank:
    value: 8
max_length:
    value: 256
max_new_tokens:
    value: 64
model_name:
    value: Qwen/Qwen2-0.5B-Instruct
num_epochs:
    value: 3
save_steps:
    value: 500
warmup_steps:
    value: 100
weight_decay:
    value: 0.01
